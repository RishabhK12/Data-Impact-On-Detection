from tflite_support.task import vision
from tflite_support.task import core
from tflite_support.task import processor
from tflite_support.metadata_writers import object_detector
from tflite_support.metadata_writers import writer_utils
import cv2

ObjectDetectorWriter = object_detector.MetadataWriter
_MODEL_PATH = "Models/DiverseModel.tflite"
_LABEL_FILE = "Models/labels.txt"
_SAVE_TO_PATH = "model_metadata.tflite"
# Normalization parameters is required when reprocessing the image. It is
# optional if the image pixel values are in range of [0, 255] and the input
# tensor is quantized to uint8. 
# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)
_INPUT_NORM_MEAN = 127.5
_INPUT_NORM_STD = 127.5

# Create the metadata writer.
writer = ObjectDetectorWriter.create_for_inference(
    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],
    [_LABEL_FILE])

# Verify the metadata generated by metadata writer.
print(writer.get_metadata_json())

writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)

# **____________________________________________________________________**

base_options = core.BaseOptions(file_name=_MODEL_PATH)
detection_options = processor.DetectionOptions(max_results=2)
options = vision.ObjectDetectorOptions(base_options, detection_options)
detector = vision.ObjectDetector.create_from_options(options)

model_path = 'model_metadata.tflite'
base_options = core.BaseOptions(file_name=model_path)
detection_options = processor.DetectionOptions(score_threshold=0.9, max_results=10)
options = vision.ObjectDetectorOptions(base_options=base_options, detection_options=detection_options)
detector = vision.ObjectDetector.create_from_options(options)

# Enter the path to your image below
image_path = 'test_files/image.jpg'
image1 = cv2.imread(image_path)
image2 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)
# Run inference
image = vision.TensorImage.create_from_array(image2)
detection_result = detector.detect(image)
print(detection_result)

pic = cv2.imread(image_path)

for detection in detection_result.detections:
    bbox = detection.bounding_box
    start_point = (int(bbox.origin_x), int(bbox.origin_y))
    end_point = (int(bbox.origin_x + bbox.width), int(bbox.origin_y + bbox.height))
    color = (0, 255, 0)
    thickness = 4
      
    cv2.rectangle(pic, start_point, end_point, color, thickness)
       
    # Draw the label if necessary
    # if detection.categories:
    #     category = detection.categories[0]
    #     label = f"{category.category_name}: {category.score:.2f}"
    #     cv2.putText(image, label, (start_point[0], start_point[1] - 10), 
    #         cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)
        
annotated_image = pic

output_image_path = 'detections/detection_output.png'
cv2.imwrite(output_image_path, annotated_image)

# Display the image with bounding boxes
cv2.imshow('Detection Output', annotated_image)
while True:
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cv2.destroyAllWindows()